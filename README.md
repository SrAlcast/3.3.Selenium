# ğŸŒ¦ï¸ Laboratorio 3.3 Selenium: ExtracciÃ³n de Datos MeteorolÃ³gicos

Este repositorio contiene un Jupyter Notebook diseÃ±ado para automatizar la navegaciÃ³n web y extraer datos meteorolÃ³gicos ğŸ•µï¸â€â™‚ï¸ relacionados con cinco municipios aleatorios de una lista proporcionada de EspaÃ±a, correspondientes a los Ãºltimos 10 meses. El notebook utiliza una combinaciÃ³n de herramientas de web scraping y automatizaciÃ³n para recopilar esta informaciÃ³n de sitios web meteorolÃ³gicos.

## ğŸ› ï¸ Herramientas y librerÃ­as utilizadas

El proyecto hace uso de varias librerÃ­as populares en Python para la extracciÃ³n y manipulaciÃ³n de datos, incluyendo:

- **BeautifulSoup**: Utilizada para el scraping de contenido HTML.
- **Requests**: Empleada para hacer solicitudes HTTP y obtener el cÃ³digo HTML de las pÃ¡ginas web.
- **Pandas** y **Numpy**: Para la manipulaciÃ³n y anÃ¡lisis de datos.
- **Selenium**: Para la automatizaciÃ³n de la interacciÃ³n con navegadores web.

## ğŸš€ Funcionalidades principales del Notebook

1. **ğŸ“Œ SelecciÃ³n aleatoria de municipios**: De una lista de municipios de EspaÃ±a, se seleccionan aleatoriamente cinco municipios para extraer sus datos meteorolÃ³gicos.

2. **ğŸŒ¤ï¸ ExtracciÃ³n de datos meteorolÃ³gicos**: Se automatiza la navegaciÃ³n para obtener informaciÃ³n meteorolÃ³gica de los Ãºltimos 10 meses para cada municipio seleccionado, utilizando BeautifulSoup y Selenium.

3. **ğŸ¤– AutomatizaciÃ³n del navegador**: A travÃ©s de Selenium, se simulan interacciones con pÃ¡ginas web, como la selecciÃ³n de fechas y navegaciÃ³n entre pÃ¡ginas meteorolÃ³gicas. Esto permite extraer informaciÃ³n detallada que no estÃ¡ disponible directamente en el HTML estÃ¡tico.

4. **ğŸ“Š OrganizaciÃ³n de datos**: Los datos meteorolÃ³gicos obtenidos se organizan en estructuras de datos para facilitar su anÃ¡lisis posterior.

5. **âš ï¸ Manejo de excepciones**: Se implementan controles para manejar errores comunes en la automatizaciÃ³n, como elementos no encontrados en la pÃ¡gina o tiempos de espera excesivos.

## ğŸ’» Requisitos del sistema

Para ejecutar este notebook correctamente, es necesario instalar las siguientes dependencias:

- Python 3.7 o superior
- `beautifulsoup4`
- `requests`
- `pandas`
- `numpy`
- `selenium`
- `webdriver-manager`

Puedes instalar todas las dependencias ejecutando el siguiente comando:

```bash
pip install -r requirements.txt
```

## ğŸ“ CÃ³mo usar este proyecto

1. Clona este repositorio en tu mÃ¡quina local:

   ```bash
   git clone https://github.com/tu_usuario/tu_repositorio.git
   ```

2. Instala las dependencias:

   ```bash
   pip install -r requirements.txt
   ```

3. Ejecuta el notebook en un entorno local o en JupyterLab.

## ğŸ™Œ CrÃ©ditos

Este proyecto fue desarrollado como parte de una prÃ¡ctica en la que se aprendiÃ³ a utilizar las herramientas mencionadas para la automatizaciÃ³n y scraping web.
